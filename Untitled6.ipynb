{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ2I2M7v5UnjKKFxf26iV+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinithkumar2006/Naan-muthalvan/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8kateuWQYKV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import threading\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "from playsound import playsound\n",
        "from ultralytics import YOLO\n",
        "import simpleaudio as sa\n",
        "\n",
        "\n",
        "# OS-based sound module\n",
        "import platform\n",
        "if platform.system() == \"Windows\":\n",
        "    import winsound  # Windows beep sound\n",
        "    sa = None   #prevents undefined variable issues\n",
        "\n",
        "else:\n",
        "    import simpleaudio as sa  # Linux/Mac alternative\n",
        "\n",
        "# ------------------------------- DRIVER MONITORING SETUP -------------------------------\n",
        "print(\"Initializing Driver Monitoring...\")\n",
        "\n",
        "# Initialize Mediapipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "# Eye landmarks\n",
        "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "\n",
        "# Alert thresholds\n",
        "EYE_CLOSED_FRAMES = 0\n",
        "EYE_CLOSED_THRESHOLD = 30  # Adjust based on FPS (~1 sec if FPS=30)\n",
        "HEAD_TILT_THRESHOLD = 25  # Maximum angle for head tilt alert\n",
        "ALARM_ON = False  # Prevent multiple alarms\n",
        "\n",
        "# Open driver camera (First Camera - Index 0)\n",
        "driver_cam = cv2.VideoCapture(0)\n",
        "if not driver_cam.isOpened():\n",
        "    print(\"Error: Could not open driver camera!\")\n",
        "    exit()\n",
        "print(\"Driver camera opened successfully!\")\n",
        "\n",
        "def play_alarm():\n",
        "    \"\"\"Plays alarm sound in a separate thread\"\"\"\n",
        "    global ALARM_ON\n",
        "    try:\n",
        "        if not ALARM_ON:\n",
        "            ALARM_ON = True\n",
        "            threading.Thread(target=lambda: playsound(\"beep.mp3\"), daemon=True).start()\n",
        "    except Exception as e:\n",
        "        print(f\"Error playing alarm: {e}\")\n",
        "        # Fallback to system beep if sound file fails\n",
        "        print('\\a')\n",
        "\n",
        "# Eye Aspect Ratio Calculation\n",
        "def eye_aspect_ratio(eye_landmarks, frame_shape):\n",
        "    \"\"\"Calculate Eye Aspect Ratio (EAR) to detect blinking\"\"\"\n",
        "    eye = np.array([(int(landmark.x * frame_shape[1]), int(landmark.y * frame_shape[0])) for landmark in eye_landmarks])\n",
        "\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "\n",
        "    return (A + B) / (2.0 * C)\n",
        "\n",
        "# Head Tilt Calculation\n",
        "def head_tilt_angle(face_landmarks, frame_shape):\n",
        "    \"\"\"Calculate head tilt based on left and right eye midpoint\"\"\"\n",
        "    left_eye = np.array([int(face_landmarks[LEFT_EYE[0]].x * frame_shape[1]), int(face_landmarks[LEFT_EYE[0]].y * frame_shape[0])])\n",
        "    right_eye = np.array([int(face_landmarks[RIGHT_EYE[0]].x * frame_shape[1]), int(face_landmarks[RIGHT_EYE[0]].y * frame_shape[0])])\n",
        "\n",
        "    return np.degrees(np.arctan2(right_eye[1] - left_eye[1], right_eye[0] - left_eye[0]))\n",
        "\n",
        "# ------------------------------- TRAFFIC MONITORING SETUP -------------------------------\n",
        "print(\"Initializing Traffic Monitoring...\")\n",
        "\n",
        "# Ensure YOLO model exists\n",
        "model_path = \"yolov8n.pt\"\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Error: YOLO model '{model_path}' not found. Download it first!\")\n",
        "    exit()\n",
        "\n",
        "# Load YOLOv8 model\n",
        "traffic_model = YOLO(model_path)\n",
        "\n",
        "# Open traffic camera (Second Camera - Index 1)\n",
        "traffic_cam = cv2.VideoCapture(1)\n",
        "if not traffic_cam.isOpened():\n",
        "    print(\"Error: Could not open traffic camera!\")\n",
        "    exit()\n",
        "print(\"Traffic camera opened successfully!\")\n",
        "\n",
        "# Objects to monitor\n",
        "ALERT_CLASSES = {0: \"Person\", 1: \"Bicycle\", 2: \"Car\", 3: \"Motorcycle\", 5: \"Bus\", 7: \"Truck\"}\n",
        "\n",
        "# Distance estimation\n",
        "def estimate_distance(bbox_width, known_width=1.8, focal_length=600):\n",
        "    return float('inf') if bbox_width == 0 else (known_width * focal_length) / bbox_width\n",
        "\n",
        "# ------------------------------- MULTITHREADING FUNCTIONS -------------------------------\n",
        "\n",
        "def driver_monitoring():\n",
        "    global EYE_CLOSED_FRAMES, ALARM_ON, driver_cam\n",
        "\n",
        "    while True:\n",
        "        ret, frame = driver_cam.read()\n",
        "\n",
        "        # If camera fails, try to reinitialize\n",
        "        if not ret:\n",
        "            print(\"Warning: Driver camera disconnected! Reinitializing...\")\n",
        "            driver_cam.release()\n",
        "            time.sleep(2)  # Wait before reinitializing\n",
        "            driver_cam = cv2.VideoCapture(0)\n",
        "            continue  # Skip this loop iteration\n",
        "\n",
        "        # Rest of the code remains unchanged...\n",
        "\n",
        "\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = face_mesh.process(frame_rgb)\n",
        "\n",
        "        if results.multi_face_landmarks:\n",
        "            for face_landmarks in results.multi_face_landmarks:\n",
        "                left_eye_ear = eye_aspect_ratio([face_landmarks.landmark[i] for i in LEFT_EYE], frame.shape)\n",
        "                right_eye_ear = eye_aspect_ratio([face_landmarks.landmark[i] for i in RIGHT_EYE], frame.shape)\n",
        "                avg_ear = (left_eye_ear + right_eye_ear) / 2\n",
        "\n",
        "                if avg_ear < 0.2:\n",
        "                    EYE_CLOSED_FRAMES += 1\n",
        "                    if EYE_CLOSED_FRAMES > EYE_CLOSED_THRESHOLD:\n",
        "                        cv2.putText(frame, \"ALERT! WAKE UP!\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
        "                        play_alarm()\n",
        "                else:\n",
        "                    EYE_CLOSED_FRAMES = 0\n",
        "                    ALARM_ON = False\n",
        "\n",
        "                tilt_angle = head_tilt_angle(face_landmarks.landmark, frame.shape)\n",
        "                if abs(tilt_angle) > HEAD_TILT_THRESHOLD:\n",
        "                    cv2.putText(frame, \"WARNING: HEAD TILT!\", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
        "                    play_alarm()\n",
        "\n",
        "        cv2.imshow(\"Driver Monitoring\", frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "def traffic_monitoring():\n",
        "    while traffic_cam.isOpened():\n",
        "        ret, frame = traffic_cam.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = traffic_model(frame)\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        for result in results:\n",
        "            for obj in result.boxes.data:\n",
        "                x1, y1, x2, y2, conf, cls = obj.tolist()\n",
        "                cls = int(cls)\n",
        "\n",
        "                if cls in ALERT_CLASSES:\n",
        "                    obj_name = ALERT_CLASSES[cls]\n",
        "                    bbox_width = x2 - x1\n",
        "                    distance = estimate_distance(bbox_width)\n",
        "\n",
        "                    if distance < 2.0:\n",
        "                        cv2.putText(annotated_frame, f\"âš  {obj_name} Too Close!\",\n",
        "                                    (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "                        play_alarm()\n",
        "\n",
        "        cv2.imshow(\"Traffic Monitoring\", annotated_frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "# ------------------------------- RUNNING BOTH MONITORS SIMULTANEOUSLY -------------------------------\n",
        "t1 = threading.Thread(target=driver_monitoring)\n",
        "t2 = threading.Thread(target=traffic_monitoring)\n",
        "\n",
        "t1.start()\n",
        "t2.start()\n",
        "\n",
        "t1.join()\n",
        "t2.join()\n",
        "\n",
        "# Release resources\n",
        "driver_cam.release()\n",
        "traffic_cam.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ]
}